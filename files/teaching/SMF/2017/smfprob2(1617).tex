%smfprob3.tex 23.12.2010 Was 16.5.2012
\documentclass[12pt]{article}
\begin{document}
\def\ni{\noindent}
\def\i{\indent}
\def\a{\alpha}
\def\b{\beta}
\def\e{\epsilon}
\def\d{\delta}
\def\g{\gamma}
\def\qq{\qquad}
\def\L{\Lambda}
\def\C{\cal C}
\def\E{\cal E}
\def\G{\Gamma}
\def\F{\cal F}
\def\K{\cal K}
\def\O{\cal O}
\def\A{\cal A}
\def\B{\cal B}
\def\S{\cal S}
\def\N{\cal N}
\def\M{\cal M}
\def\P{\cal P}
\def\Om{\Omega}
\def\om{\omega}
\def\s{\sigma}
\def\t{\theta}
\def\z{\zeta}
\def\p{\phi}
\def\m{\mu}
\def\n{\nu}
\def\b{\beta}
\def\e{\epsilon}
\def\l{\lambda}
\def\Si{\Sigma}
\def\half{\frac{1}{2}}
\def\hb{\hfil \break}
\ni smfprob2(1617).tex \\
\begin{center}
{\bf SMF PROBLEMS 2.  26.1.2017} \\
\end{center}

\ni Q1 ({\it Conditions for equality in the Cram\'er-Rao (Information, CR) Inequality}). \\
(i) Show that in the Cauchy-Schwarz Inequality
$$
(\int fg)^2 \leq (\int f^2)(\int g^2),
$$
equality holds iff there is a linear relationship between $f$ and $g$:
$$
af + bg = 0
$$
for some constants $a, b$. \\
(ii) Deduce that we have equality in CR iff
$$
u = a {\ell}' + b
$$
for some $a,b$.  Find $b$. \\
(iii) Observing that the constant $a$ above may depend on the parameter $\t$, and that when we integrate ${\ell}'$ to get $\ell$, $L$ the constant of integration may depend on the data $\bf X$, show that equality holds iff $L$ has the form
$$
L = \exp \{ \a(\t) u({\bf X}) + \b(\t) + k({\bf X}) \}.
$$
Such likelihoods form the {\it exponential family} -- roughly, the families for which one can do parameter estimation satisfactorily. \\
(iv) Show that $u({\bf X})$ is (a) sufficient for $\t$; (b) minimal sufficient for $\t$. \\

\ni Q2 ({\it Symmetric exponential location family}).  Here
$$
f(x) = \half \exp \{ |x - \t | \}.
$$
(i) Show that
$$
\ell = const - \sum |x_i - \t|.
$$
Show that this is maximised where $\t$ is the {\it median} of the sample, $Med = Med(x_1, \ldots, x_n)$, and deduce that this is the MLE:
$$
\hat{\m} = Med.
$$
(ii) Show that the information per reading is 1 (use $I = \int (\partial \log f/\partial \t)^2 f$). \\
\i We quote that the sample median $Med$ is asymptotically normal with mean the (population) median $med$ and variance $1/(4 n f(med)^2)$. \\
(iii) Show that $Med$ is asymptotically normal, unbiased and efficient. \\

\ni Q3 ({\it Cauchy location family}).  The Cauchy location family is defined by
$$
f(x; \m) = \frac{1}{\pi(1 + (x - \m)^2)}.
$$
(i) Show that this does not belong to the exponential family (it is a standard example of this!) \\
(ii) Show that the MLE has asymptotic variance
$$
var(\hat{\m}) \sim 2/n
$$
and efficiency $8/{\pi}^2$ ($\sim 81\%$).
You may quote that
$$
I := \int_{-\infty}^{\infty} \frac{x^2}{[1 + x^2]^3} dx = \half.
$$
\hfil NHB \break




\end{document}

\ni Q1.  The $AR(p)$ process $(X_t)$ is given by
$$
X_t = {\phi}_1 X_{t-1} + \cdots + {\phi}_p X_{t-p}, \qquad
({\e}_t) \quad WN({\sigma}^2).
$$
(i) State without proof the condition for stationarity. \\
(ii) Derive the Yule-Walker equations for the autocorrelation $({\rho}_k)$. \\
(iii) State the general solution of the Yule-Walker equations.\\

\ni Q2.  The $MA(1)$ process $(X_t)$ is given by
$$
X_t = {\e}_t + \theta {\e}_{t-1}, \qquad |\theta| < 1, \qquad
({\e}_t) \quad WN({\sigma}^2).
$$
Find \\
(i) the variance ${\gamma}_0 = var X_t$, \\
(ii) the autocovariance ${\gamma}_k = cov(X_t, X_{t+k})$, \\
(iii) the autocorrelation ${\rho}_k = corr(X_t, X_{t+k})$.\\

\ni Q3.  The time-series model is given by
$$
X_t = X_{t-1} - {1 \over 4} X_{t-2} + {\e}_t + {1 \over 2} {\e}_{t-1},
 \qquad ({\e}_t) \quad WN({\sigma}^2).
$$
(i) Classify $(X_t)$ within the $ARIMA$ class. \\
(ii) Show that $(X_t)$ is stationary and invertible.\\

\hfil NHB \break


\end{document}
